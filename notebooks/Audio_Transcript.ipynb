{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ac0f39",
   "metadata": {},
   "source": [
    "# $Audio Transcript$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cafe56",
   "metadata": {},
   "source": [
    "## `01` Import Libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2836254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d729151",
   "metadata": {},
   "source": [
    "## `02` API setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "766c3e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../.env') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d32356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\") # replace by yours\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdd0db",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a434028",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ad371",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97d99d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../outputs/keyframes/keyframe_0002.jpg'\n",
    "output_csv_file = \"../outputs/image_analysis_results_combined.csv\"\n",
    "csv_headers = [\"Image Name\", \"Extracted Text\", \"Visual Description\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62976b10",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c77c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_image(original_path):\n",
    "    \"\"\"\n",
    "    This function loads an image and returns an in-memory copy of it.\n",
    "    It does not save anything to disk. \n",
    "    Parameters:\n",
    "        original_path (str): The path to the original image file.\n",
    "    Returns:\n",
    "        PIL.Image: An in-memory copy of the original image.\n",
    "    \"\"\"\n",
    "    original = Image.open(original_path)\n",
    "    buffer = BytesIO()\n",
    "    original.save(buffer, format=original.format)  # Save to memory buffer\n",
    "    buffer.seek(0)\n",
    "    return Image.open(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output_to_rows(model_output_text, output_csv_file= output_csv_file, csv_headers= csv_headers):\n",
    "    \"\"\"\n",
    "    This function parses the model's output string from a labeled text format (e.g., \"Image Name: ... Extracted Text: ...\")\n",
    "    into a dictionary that can be written to a CSV file. It extracts the image name,\n",
    "    extracted text, and visual description from the model's output.\n",
    "    Parameters:\n",
    "        model_output_text (str): The output text from the model containing labeled information.\n",
    "        output_csv_file (str): The path to the CSV file where the data will be saved\n",
    "        csv_headers (list): The headers for the CSV file.\n",
    "    Returns:\n",
    "        bool: True if the data was successfully saved to the CSV file, False otherwise.\n",
    "    \"\"\"\n",
    "    image_name_match = re.search(r'Image Name:\\s*(.*?)\\s*Extracted Text:', model_output_text, re.DOTALL)\n",
    "    extracted_text_match = re.search(r'Extracted Text:\\s*(.*?)\\s*Visual Description:', model_output_text, re.DOTALL)\n",
    "    visual_description_match = re.search(r'Visual Description:\\s*(.*)', model_output_text, re.DOTALL)\n",
    "\n",
    "    image_name = \"N/A\"\n",
    "    extracted_text = \"N/A\"\n",
    "    visual_description = \"N/A\"\n",
    "\n",
    "    if image_name_match:\n",
    "        image_name = image_name_match.group(1).strip()\n",
    "    if extracted_text_match:\n",
    "        extracted_text = extracted_text_match.group(1).strip()\n",
    "        extracted_text = extracted_text.replace(\"<br>\", \"\\n\").replace(\"<br/>\", \"\\n\")\n",
    "    if visual_description_match:\n",
    "        visual_description = visual_description_match.group(1).strip()\n",
    "\n",
    "    row_to_save = {}\n",
    "    if image_name != \"N/A\" or extracted_text != \"N/A\" or visual_description != \"N/A\":\n",
    "        row_to_save = {\n",
    "            \"Image Name\": image_name,\n",
    "            \"Extracted Text\": extracted_text,\n",
    "            \"Visual Description\": visual_description\n",
    "        }\n",
    "    else:\n",
    "        print(\"Warning: Could not parse model output into expected labeled format.\")\n",
    "        print(\"Raw model output:\\n\", model_output_text)\n",
    "        row_to_save = {\"Image Name\": \"Parsing Error\", \"Extracted Text\": model_output_text, \"Visual Description\": \"Error during parsing\"}\n",
    "\n",
    "    try:\n",
    "        file_exists = os.path.exists(output_csv_file)\n",
    "        write_header = not file_exists or os.path.getsize(output_csv_file) == 0\n",
    "\n",
    "        with open(output_csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=csv_headers)\n",
    "\n",
    "            if write_header:\n",
    "                writer.writeheader()\n",
    "\n",
    "            writer.writerow(row_to_save)\n",
    "\n",
    "        print(f\"Data for '{image_name}' appended to {output_csv_file}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data for '{image_name}' to CSV: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0a0b02",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_dummy_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa8dccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: Machine Learning Diagram\n",
      "Extracted Text: التعليم باشراف و بدون اشراف \"Machine Learning\"  \"SUPERVISED LEARNING\" \"Develop predictive model based on both input and output data\" \"CLASSIFICATION\" \"REGRESSION\" \"UNSUPERVISED LEARNING\" \"Group and interpret data based only on input data\" \"CLUSTERING\"  \"MACHINE LEARNING\"\n",
      "Visual Description: The image contains a flowchart.  The central box shows \"MACHINE LEARNING\".  Arrows branch out to two boxes representing \"SUPERVISED LEARNING\" and \"UNSUPERVISED LEARNING\". Each of these boxes contains a short description of the learning type.  Further arrows from \"SUPERVISED LEARNING\" point to \"CLASSIFICATION\" and \"REGRESSION\". An arrow from \"UNSUPERVISED LEARNING\" points to \"CLUSTERING\".  All boxes are rectangular.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content([\n",
    "    \"Analyze the provided images to extract all textual content. \",\n",
    "    \"If the text is in Arabic, transcribe it in Arabic and provide an English translation in quotation marks immediately following the Arabic text. \",\n",
    "    \"If the text is entirely in English, transcribe it as is. \",\n",
    "    \"If the text is predominantly Arabic with some English words, transcribe the Arabic and enclose the English words in quotation marks within the Arabic transcription. \",\n",
    "    \"Additionally, identify and describe any *embedded, informative visuals* within the images that convey data or information. \",\n",
    "    \"This specifically includes elements such as graphs, charts, tables of text, histograms, flowcharts, diagrams, or other visual representations of data. \",\n",
    "    \"Do NOT describe the overall image design, background, or purely decorative elements. \",\n",
    "    \"Structure the output as follows, with each image's information presented in a clear, column-like format: \",\n",
    "    \"Image Name: [Name of Image File]\",\n",
    "    \"Extracted Text: [Transcribed text as per language rules, with English translations/quoted English words]\",\n",
    "    \"Visual Description: [Detailed description of any embedded, informative visuals present. State 'None' if no such visuals are found.]\",\n",
    "    img, \n",
    "])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 'Machine Learning Diagram' appended to ../outputs/image_analysis_results_combined.csv\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "parsed_data = parse_model_output_to_rows(response.text)\n",
    "print(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e4ffa12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Image Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Extracted Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Visual Description",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4cd161e6-e505-4e0e-9af5-bc302dba87d7",
       "rows": [
        [
         "0",
         "Machine Learning Diagram",
         "التعليم باشراف و بدون اشراف \"Machine Learning\"  \"SUPERVISED LEARNING\" \"Develop predictive model based on both input and output data\" \"CLASSIFICATION\" \"REGRESSION\" \"UNSUPERVISED LEARNING\" \"Group and interpret data based only on input data\" \"CLUSTERING\"  \"MACHINE LEARNING\"",
         "The image contains a flowchart.  The central box shows \"MACHINE LEARNING\".  Arrows branch out to two boxes representing \"SUPERVISED LEARNING\" and \"UNSUPERVISED LEARNING\". Each of these boxes contains a short description of the learning type.  Further arrows from \"SUPERVISED LEARNING\" point to \"CLASSIFICATION\" and \"REGRESSION\". An arrow from \"UNSUPERVISED LEARNING\" points to \"CLUSTERING\".  All boxes are rectangular."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Extracted Text</th>\n",
       "      <th>Visual Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Diagram</td>\n",
       "      <td>التعليم باشراف و بدون اشراف \"Machine Learning\"...</td>\n",
       "      <td>The image contains a flowchart.  The central b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Image Name  \\\n",
       "0  Machine Learning Diagram   \n",
       "\n",
       "                                      Extracted Text  \\\n",
       "0  التعليم باشراف و بدون اشراف \"Machine Learning\"...   \n",
       "\n",
       "                                  Visual Description  \n",
       "0  The image contains a flowchart.  The central b...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(output_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e12bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4cc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
