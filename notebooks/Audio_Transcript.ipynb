{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ac0f39",
   "metadata": {},
   "source": [
    "# $Audio Transcript$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cafe56",
   "metadata": {},
   "source": [
    "## `01` Import Libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2836254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d729151",
   "metadata": {},
   "source": [
    "## `02` API setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "766c3e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../.env') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d32356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\") # replace by yours\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdd0db",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a434028",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ad371",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97d99d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Image.open('../outputs/keyframes/keyframe_0002.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62976b10",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_images():\n",
    "    # Replace this with your actual image loading logic\n",
    "    # For demonstration, we'll just use a placeholder\n",
    "    return [\"image_data_for_Image1.jpg\", \"image_data_for_Image2.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output_to_rows(model_output_text):\n",
    "    \"\"\"\n",
    "    Parses the model's output string (which is expected to be a Markdown table)\n",
    "    into a list of dictionaries, where each dictionary represents a row for the CSV.\n",
    "\n",
    "    This function needs to be adapted if the model's output format changes.\n",
    "    \"\"\"\n",
    "    parsed_rows = []\n",
    "\n",
    "    # This regex attempts to capture the data from a single row in the Markdown table format.\n",
    "    # It looks for: | any characters (non-pipe) | any characters (non-pipe) | any characters (non-pipe) |\n",
    "    # re.DOTALL allows '.' to match newlines, important if text fields contain line breaks.\n",
    "    match = re.search(r'\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|', model_output_text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        # Group 1: Image Name (e.g., \"Image 1\")\n",
    "        image_name = match.group(1).strip()\n",
    "        # Group 2: Extracted Text (e.g., \"فرع تعلم الآلة ...\")\n",
    "        extracted_text = match.group(2).strip()\n",
    "        # Group 3: Visual Description (e.g., \"None\")\n",
    "        visual_description = match.group(3).strip()\n",
    "\n",
    "        # Clean up any HTML break tags (<br>, <br/>) from the extracted text\n",
    "        # and replace them with actual newlines for better CSV readability.\n",
    "        extracted_text = extracted_text.replace(\"<br>\", \"\\n\").replace(\"<br/>\", \"\\n\")\n",
    "\n",
    "        # Add the extracted data as a dictionary to our list of rows\n",
    "        parsed_rows.append({\n",
    "            \"Image Name\": image_name,\n",
    "            \"Extracted Text\": extracted_text,\n",
    "            \"Visual Description\": visual_description\n",
    "        })\n",
    "    else:\n",
    "        # If the regex doesn't find a match, it means the model's output\n",
    "        # wasn't in the expected Markdown table format.\n",
    "        print(\"Warning: Could not parse model output into expected format. Check 'simulated_model_response_text' or actual model output format.\")\n",
    "        print(\"Raw model output:\\n\", model_output_text)\n",
    "        # As a fallback, we add an entry indicating a parsing error\n",
    "        parsed_rows.append({\"Image Name\": \"Parsing Error\", \"Extracted Text\": model_output_text, \"Visual Description\": \"Error during parsing\"})\n",
    "\n",
    "    return parsed_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0a0b02",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8dccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: Machine Learning Diagram\n",
      "Extracted Text: التعلم باشراف و بدون اشراف \"Machine Learning\"\n",
      "Visual Description: The image contains a flowchart. The central node is labeled \"MACHINE LEARNING\".  Two branches stem from this node: \"SUPERVISED LEARNING\" (with the description \"Develop predictive model based on both input and output data\") and \"UNSUPERVISED LEARNING\" (with the description \"Group and interpret data based only on input data\").  Each of these branches further splits into three sub-branches:  \"SUPERVISED LEARNING\" branches into \"CLASSIFICATION\", \"REGRESSION\", and an unnamed node; and \"UNSUPERVISED LEARNING\" branches into \"CLUSTERING\" and two unnamed nodes.  The flowchart visually represents the hierarchical relationship between machine learning and its subcategories.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content([\n",
    "    \"Analyze the provided images to extract all textual content. \",\n",
    "    \"If the text is in Arabic, transcribe it in Arabic and provide an English translation in quotation marks immediately following the Arabic text. \",\n",
    "    \"If the text is entirely in English, transcribe it as is. \",\n",
    "    \"If the text is predominantly Arabic with some English words, transcribe the Arabic and enclose the English words in quotation marks within the Arabic transcription. \",\n",
    "    \"Additionally, identify and describe any *embedded, informative visuals* within the images that convey data or information. \",\n",
    "    \"This specifically includes elements such as graphs, charts, tables of text, histograms, flowcharts, diagrams, or other visual representations of data. \",\n",
    "    \"Do NOT describe the overall image design, background, or purely decorative elements. \",\n",
    "    \"Structure the output as follows, with each image's information presented in a clear, column-like format: \",\n",
    "    \"Image Name: [Name of Image File]\",\n",
    "    \"Extracted Text: [Transcribed text as per language rules, with English translations/quoted English words]\",\n",
    "    \"Visual Description: [Detailed description of any embedded, informative visuals present. State 'None' if no such visuals are found.]\",\n",
    "    \"\", # An empty string for separation if needed, or remove if not desired\n",
    "    images\n",
    "])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba3db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e12bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4cc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
