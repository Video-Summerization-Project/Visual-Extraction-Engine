{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ac0f39",
   "metadata": {},
   "source": [
    "# $Audio Transcript$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cafe56",
   "metadata": {},
   "source": [
    "## `01` Import Libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d729151",
   "metadata": {},
   "source": [
    "## `02` API setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "766c3e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../.env') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d32356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\") # replace by yours\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cdd0db",
   "metadata": {},
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a434028",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ad371",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97d99d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../outputs/keyframes/keyframe_0002.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62976b10",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c77c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_image(original_path):\n",
    "    \"\"\"\n",
    "    This function loads an image and returns an in-memory copy of it.\n",
    "    It does not save anything to disk. \n",
    "    Parameters:\n",
    "        original_path (str): The path to the original image file.\n",
    "    Returns:\n",
    "        PIL.Image: An in-memory copy of the original image.\n",
    "    \"\"\"\n",
    "    original = Image.open(original_path)\n",
    "    buffer = BytesIO()\n",
    "    original.save(buffer, format=original.format)  # Save to memory buffer\n",
    "    buffer.seek(0)\n",
    "    return Image.open(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8001af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_dummy_image(image_path)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a34eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_output_to_rows(model_output_text):\n",
    "    \"\"\"\n",
    "    Parses the model's output string (which is expected to be a Markdown table)\n",
    "    into a list of dictionaries, where each dictionary represents a row for the CSV.\n",
    "\n",
    "    This function needs to be adapted if the model's output format changes.\n",
    "    \"\"\"\n",
    "    parsed_rows = []\n",
    "\n",
    "    # This regex attempts to capture the data from a single row in the Markdown table format.\n",
    "    # It looks for: | any characters (non-pipe) | any characters (non-pipe) | any characters (non-pipe) |\n",
    "    # re.DOTALL allows '.' to match newlines, important if text fields contain line breaks.\n",
    "    match = re.search(r'\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|\\s*([^|]+?)\\s*\\|', model_output_text, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        # Group 1: Image Name (e.g., \"Image 1\")\n",
    "        image_name = match.group(1).strip()\n",
    "        # Group 2: Extracted Text (e.g., \"فرع تعلم الآلة ...\")\n",
    "        extracted_text = match.group(2).strip()\n",
    "        # Group 3: Visual Description (e.g., \"None\")\n",
    "        visual_description = match.group(3).strip()\n",
    "\n",
    "        # Clean up any HTML break tags (<br>, <br/>) from the extracted text\n",
    "        # and replace them with actual newlines for better CSV readability.\n",
    "        extracted_text = extracted_text.replace(\"<br>\", \"\\n\").replace(\"<br/>\", \"\\n\")\n",
    "\n",
    "        # Add the extracted data as a dictionary to our list of rows\n",
    "        parsed_rows.append({\n",
    "            \"Image Name\": image_name,\n",
    "            \"Extracted Text\": extracted_text,\n",
    "            \"Visual Description\": visual_description\n",
    "        })\n",
    "    else:\n",
    "        # If the regex doesn't find a match, it means the model's output\n",
    "        # wasn't in the expected Markdown table format.\n",
    "        print(\"Warning: Could not parse model output into expected format. Check 'simulated_model_response_text' or actual model output format.\")\n",
    "        print(\"Raw model output:\\n\", model_output_text)\n",
    "        # As a fallback, we add an entry indicating a parsing error\n",
    "        parsed_rows.append({\"Image Name\": \"Parsing Error\", \"Extracted Text\": model_output_text, \"Visual Description\": \"Error during parsing\"})\n",
    "\n",
    "    return parsed_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea0a0b02",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8dccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: Machine Learning Diagram\n",
      "Extracted Text: التعليم باشراف و بدون اشراف \"Machine Learning\"  \"SUPERVISED LEARNING\" \"Develop predictive model based on both input and output data\" \"CLASSIFICATION\" \"REGRESSION\" \"UNSUPERVISED LEARNING\" \"Group and interpret data based only on input data\" \"CLUSTERING\"  \"MACHINE LEARNING\"\n",
      "Visual Description: The image contains a flowchart.  The flowchart depicts a hierarchical structure of machine learning, starting with a central box labeled \"MACHINE LEARNING\". This box branches into two main categories: \"SUPERVISED LEARNING\" and \"UNSUPERVISED LEARNING\".  \"SUPERVISED LEARNING\" further branches into \"CLASSIFICATION\" and \"REGRESSION\", while \"UNSUPERVISED LEARNING\" branches into \"CLUSTERING\".  Each branch is represented by an arrow, showing the relationship between the concepts.  The descriptions within each box provide a short definition of the respective machine learning type.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content([\n",
    "    \"Analyze the provided images to extract all textual content. \",\n",
    "    \"If the text is in Arabic, transcribe it in Arabic and provide an English translation in quotation marks immediately following the Arabic text. \",\n",
    "    \"If the text is entirely in English, transcribe it as is. \",\n",
    "    \"If the text is predominantly Arabic with some English words, transcribe the Arabic and enclose the English words in quotation marks within the Arabic transcription. \",\n",
    "    \"Additionally, identify and describe any *embedded, informative visuals* within the images that convey data or information. \",\n",
    "    \"This specifically includes elements such as graphs, charts, tables of text, histograms, flowcharts, diagrams, or other visual representations of data. \",\n",
    "    \"Do NOT describe the overall image design, background, or purely decorative elements. \",\n",
    "    \"Structure the output as follows, with each image's information presented in a clear, column-like format: \",\n",
    "    \"Image Name: [Name of Image File]\",\n",
    "    \"Extracted Text: [Transcribed text as per language rules, with English translations/quoted English words]\",\n",
    "    \"Visual Description: [Detailed description of any embedded, informative visuals present. State 'None' if no such visuals are found.]\",\n",
    "    img, \n",
    "])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba3db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ffa12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e12bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4cc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
