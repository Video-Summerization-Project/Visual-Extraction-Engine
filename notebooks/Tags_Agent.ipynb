{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDj6fwKXFT9z"
      },
      "source": [
        "# importing libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BM6wAP2QE_JW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import csv\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from typing import Dict, List, Any, TypedDict, Literal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2abpmctBE_IM"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X0g-7MGFMJ3"
      },
      "source": [
        "# Create output directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hehpQpGNE_Ds"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"output\", exist_ok=True)\n",
        "output_csv_file = \"output/video_summary_results.csv\"\n",
        "output_json_file = \"output/frame_importance.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebm1Li6UFid2"
      },
      "source": [
        "# Initialize the Gemini model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nk9-9RYME_Ck"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QramFbvE-9n"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.1,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXoVKH2vFmwj"
      },
      "source": [
        "# Define graph state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define graph state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msRosIyUE-8j"
      },
      "outputs": [],
      "source": [
        "# Helper function to convert image to base64\n",
        "def image_to_base64(image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        buffered = BytesIO()\n",
        "        img.save(buffered, format=img.format if img.format else \"JPEG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "        mime_type = f\"image/{img.format.lower()}\" if img.format else \"image/jpeg\"\n",
        "        return img_str, mime_type\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting image to base64: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "# Helper function to describe frames directly - NO RETRY\n",
        "def describe_frame_directly(frame_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"Describe a frame directly without using the workflow\"\"\"\n",
        "    # Convert image to base64\n",
        "    img_str, mime_type = image_to_base64(frame_path)\n",
        "    if not img_str:\n",
        "        return {\n",
        "            \"image_name\": os.path.basename(frame_path),\n",
        "            \"extracted_text\": \"Failed to process image\",\n",
        "            \"visual_description\": \"Error occurred during image processing\",\n",
        "            \"error\": \"Image conversion failed\"\n",
        "        }\n",
        "\n",
        "    # Call the model directly - NO RETRY\n",
        "    prompt = f\"\"\"\n",
        "        You are an expert in multilingual document understanding.\n",
        "\n",
        "        Your task is to extract and analyze text and informative visual elements from the given image.\n",
        "\n",
        "        Rules:\n",
        "          - Analyze the provided image to extract all textual content.\n",
        "          - If text is in Arabic, copy it in Arabic and provide an English translation in quotes immediately after the Arabic text.\n",
        "          - If text is entirely in English, copy it as is.\n",
        "          - If text is primarily Arabic with some English words, copy the Arabic text and place the English words in quotes within the Arabic text.\n",
        "          - Additionally, identify any informative visual elements in the image that convey data or information.\n",
        "          - This specifically includes elements such as charts, diagrams, text tables, histograms, flowcharts, illustrations, or other visual representations of data.\n",
        "          - Do not describe the general image design, background, or purely decorative elements.\n",
        "          - Translate the visual description to Arabic and remove English after translation.\n",
        "          - Structure your output as follows, presenting the image information in a clear vertical format:\n",
        "\n",
        "        Image Name: {os.path.basename(frame_path)}\n",
        "        Extracted Text: [Copied text according to language rules, with English translations/quoted English words]\n",
        "        Visual Description: [Detailed description of any informative visual elements present. State 'None' if no such visual elements are found.]\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        messages = [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mime_type};base64,{img_str}\"}}\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Direct API call - NO RETRY\n",
        "        response = model.invoke(messages)\n",
        "        output_text = response.content.strip()\n",
        "\n",
        "        # Extract information using regex\n",
        "        image_name_match = re.search(r'Image Name:\\s*(.*?)\\s*Extracted Text:', output_text, re.DOTALL) or \\\n",
        "                          re.search(r'اسم الصورة:\\s*(.*?)\\s*النص المستخرج:', output_text, re.DOTALL)\n",
        "\n",
        "        extracted_text_match = re.search(r'Extracted Text:\\s*(.*?)\\s*Visual Description:', output_text, re.DOTALL) or \\\n",
        "                              re.search(r'النص المستخرج:\\s*(.*?)\\s*الوصف المرئي:', output_text, re.DOTALL)\n",
        "\n",
        "        visual_description_match = re.search(r'Visual Description:\\s*(.*)', output_text, re.DOTALL) or \\\n",
        "                                  re.search(r'الوصف المرئي:\\s*(.*)', output_text, re.DOTALL)\n",
        "\n",
        "        return {\n",
        "            \"image_name\": image_name_match.group(1).strip() if image_name_match else os.path.basename(frame_path),\n",
        "            \"extracted_text\": extracted_text_match.group(1).strip() if extracted_text_match else \"No text found\",\n",
        "            \"visual_description\": visual_description_match.group(1).strip() if visual_description_match else \"No visual description\",\n",
        "            \"raw_output\": output_text\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error describing frame: {str(e)}\")\n",
        "        return {\n",
        "            \"image_name\": os.path.basename(frame_path),\n",
        "            \"extracted_text\": \"Error occurred\",\n",
        "            \"visual_description\": f\"Failed to analyze: {str(e)}\",\n",
        "            \"raw_output\": f\"Error: {str(e)}\"\n",
        "        }\n",
        "\n",
        "# Graph functions\n",
        "def extract_frame_features(state: GraphState) -> GraphState:\n",
        "    \"\"\"Extract frame features like colors, contrast, and content\"\"\"\n",
        "    frame_path = state[\"frame_path\"]\n",
        "\n",
        "    try:\n",
        "        # Read the frame\n",
        "        img = cv2.imread(frame_path)\n",
        "        if img is None:\n",
        "            state[\"frame_features\"] = {\"error\": \"Failed to load frame\"}\n",
        "            state[\"next_step\"] = \"evaluate_importance\"\n",
        "            return state\n",
        "\n",
        "        # Extract basic features\n",
        "        height, width, channels = img.shape\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Calculate contrast\n",
        "        contrast = np.std(gray)\n",
        "\n",
        "        # Calculate average brightness\n",
        "        brightness = np.mean(gray)\n",
        "\n",
        "        # Calculate ratio of black frame (very dark pixels)\n",
        "        dark_pixels = np.sum(gray < 30) / (height * width)\n",
        "\n",
        "        # Analyze colors\n",
        "        color_variance = np.var(img.reshape(-1, 3), axis=0).sum()\n",
        "\n",
        "        # Face detection (optional)\n",
        "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "        has_faces = len(faces) > 0\n",
        "\n",
        "        # Compile features\n",
        "        state[\"frame_features\"] = {\n",
        "            \"dimensions\": {\"height\": height, \"width\": width},\n",
        "            \"contrast\": float(contrast),\n",
        "            \"brightness\": float(brightness),\n",
        "            \"dark_ratio\": float(dark_pixels),\n",
        "            \"color_variance\": float(color_variance),\n",
        "            \"has_faces\": has_faces,\n",
        "            \"face_count\": len(faces),\n",
        "        }\n",
        "\n",
        "        # Convert image to base64 for sending to model\n",
        "        pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        buffered = BytesIO()\n",
        "        pil_img.save(buffered, format=\"JPEG\")\n",
        "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "        state[\"frame_data\"] = {\n",
        "            \"base64_image\": img_str,\n",
        "            \"file_name\": os.path.basename(frame_path)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting frame features: {str(e)}\")\n",
        "        state[\"frame_features\"] = {\"error\": f\"Feature extraction failed: {str(e)}\"}\n",
        "        state[\"frame_data\"] = {\"file_name\": os.path.basename(frame_path)}\n",
        "\n",
        "    state[\"next_step\"] = \"evaluate_importance\"\n",
        "    return state\n",
        "\n",
        "def evaluate_importance(state: GraphState) -> GraphState:\n",
        "    \"\"\"Evaluate frame importance using AI model\"\"\"\n",
        "\n",
        "    # If frame is mostly black, classify it directly as unimportant\n",
        "    if state[\"frame_features\"].get(\"dark_ratio\", 0) > 0.9:\n",
        "        state[\"importance\"] = \"not_important\"\n",
        "        state[\"reason\"] = \"Frame is mostly black (over 90%)\"\n",
        "        state[\"next_step\"] = END\n",
        "        return state\n",
        "\n",
        "    # Check if there was an error in feature extraction\n",
        "    if \"error\" in state[\"frame_features\"]:\n",
        "        state[\"importance\"] = \"not_important\"\n",
        "        state[\"reason\"] = f\"Could not properly analyze frame: {state['frame_features']['error']}\"\n",
        "        state[\"next_step\"] = END\n",
        "        return state\n",
        "\n",
        "    try:\n",
        "        # Prepare message for model with image\n",
        "        messages = [\n",
        "            SystemMessage(content=\"\"\"You are an expert in video summarization. Your task is to evaluate the importance of a video frame for inclusion in a video summary.\n",
        "\n",
        "            Evaluate the frame and classify it as either \"important\" or \"not_important\" based on the following criteria:\n",
        "\n",
        "            Important frames:\n",
        "            - Contain essential information for the video\n",
        "            - Show important events or scene changes\n",
        "            - Contain important text or visual information\n",
        "            - Represent key moments in the video\n",
        "\n",
        "            Unimportant frames:\n",
        "            - Black or single-color frames\n",
        "            - Regular portrait shots unrelated to video content\n",
        "            - Transitional or blurry frames\n",
        "            - Frames very similar to previous ones\n",
        "\n",
        "            Return a JSON containing:\n",
        "            {\n",
        "              \"importance\": \"important\" or \"not_important\",\n",
        "              \"reason\": \"reason for your classification\"\n",
        "            }\n",
        "            \"\"\"),\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": f\"Evaluate the importance of this video frame.\"},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{state['frame_data']['base64_image']}\"}}\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Direct API call - NO RETRY\n",
        "        response = model.invoke(messages)\n",
        "\n",
        "        # Process response\n",
        "        try:\n",
        "            # Try to extract JSON from response\n",
        "            json_match = re.search(r'({.*})', response.content.replace('\\n', ' '))\n",
        "            if json_match:\n",
        "                result = json.loads(json_match.group(1))\n",
        "                state[\"importance\"] = result.get(\"importance\", \"not_important\")\n",
        "                state[\"reason\"] = result.get(\"reason\", \"No reason provided\")\n",
        "            else:\n",
        "                # Parse text response\n",
        "                if \"important\" in response.content.lower():\n",
        "                    state[\"importance\"] = \"important\"\n",
        "                else:\n",
        "                    state[\"importance\"] = \"not_important\"\n",
        "\n",
        "                state[\"reason\"] = response.content\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing importance response: {str(e)}\")\n",
        "            state[\"importance\"] = \"not_important\"\n",
        "            state[\"reason\"] = f\"Error processing response: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating importance: {str(e)}\")\n",
        "        state[\"importance\"] = \"not_important\"\n",
        "        state[\"reason\"] = f\"Failed to evaluate: {str(e)}\"\n",
        "\n",
        "    # Determine next step based on frame importance\n",
        "    if state[\"importance\"] == \"important\":\n",
        "        state[\"next_step\"] = \"describe_frame\"\n",
        "    else:\n",
        "        state[\"next_step\"] = END\n",
        "\n",
        "    return state\n",
        "\n",
        "def describe_frame(state: GraphState) -> GraphState:\n",
        "    \"\"\"Describe important frame and extract text from it\"\"\"\n",
        "    frame_path = state[\"frame_path\"]\n",
        "\n",
        "    try:\n",
        "        # Prepare message for model with image\n",
        "        prompt = \"\"\"\n",
        "            You are an expert in multilingual document understanding.\n",
        "\n",
        "            Your task is to extract and analyze text and informative visual elements from the given image.\n",
        "\n",
        "            Rules:\n",
        "              - Analyze the provided image to extract all textual content.\n",
        "              - If text is in Arabic, copy it in Arabic and provide an English translation in quotes immediately after the Arabic text.\n",
        "              - If text is entirely in English, copy it as is.\n",
        "              - If text is primarily Arabic with some English words, copy the Arabic text and place the English words in quotes within the Arabic text.\n",
        "              - Additionally, identify any informative visual elements in the image that convey data or information.\n",
        "              - This specifically includes elements such as charts, diagrams, text tables, histograms, flowcharts, illustrations, or other visual representations of data.\n",
        "              - Do not describe the general image design, background, or purely decorative elements.\n",
        "              - Translate the visual description to Arabic if needed.\n",
        "              - Structure your output as follows, presenting the image information in a clear vertical format:\n",
        "\n",
        "            Image Name: %s\n",
        "            Extracted Text: [Copied text according to language rules, with English translations/quoted English words]\n",
        "            Visual Description: [Detailed description of any informative visual elements present. State 'None' if no such visual elements are found.]\n",
        "        \"\"\" % os.path.basename(frame_path)\n",
        "\n",
        "        # Call model with image - NO RETRY\n",
        "        messages = [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{state['frame_data']['base64_image']}\"}}\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Direct API call - NO RETRY\n",
        "                # Direct API call - NO RETRY\n",
        "        response = model.invoke(messages)\n",
        "        output_text = response.content.strip()\n",
        "\n",
        "        # Extract different sections from text\n",
        "        image_name_match = re.search(r'Image Name:\\s*(.*?)\\s*Extracted Text:', output_text, re.DOTALL) or \\\n",
        "                          re.search(r'اسم الصورة:\\s*(.*?)\\s*النص المستخرج:', output_text, re.DOTALL)\n",
        "\n",
        "        extracted_text_match = re.search(r'Extracted Text:\\s*(.*?)\\s*Visual Description:', output_text, re.DOTALL) or \\\n",
        "                              re.search(r'النص المستخرج:\\s*(.*?)\\s*الوصف المرئي:', output_text, re.DOTALL)\n",
        "\n",
        "        visual_description_match = re.search(r'Visual Description:\\s*(.*)', output_text, re.DOTALL) or \\\n",
        "                                  re.search(r'الوصف المرئي:\\s*(.*)', output_text, re.DOTALL)\n",
        "\n",
        "        # Store results\n",
        "        state[\"description\"] = {\n",
        "            \"image_name\": image_name_match.group(1).strip() if image_name_match else os.path.basename(frame_path),\n",
        "            \"extracted_text\": extracted_text_match.group(1).strip() if extracted_text_match else \"No text found\",\n",
        "            \"visual_description\": visual_description_match.group(1).strip() if visual_description_match else \"No visual description\",\n",
        "            \"raw_output\": output_text\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error describing frame: {str(e)}\")\n",
        "        state[\"description\"] = {\n",
        "            \"image_name\": os.path.basename(frame_path),\n",
        "            \"extracted_text\": \"Error processing text\",\n",
        "            \"visual_description\": \"Error generating description\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "    state[\"next_step\"] = END\n",
        "    return state\n",
        "\n",
        "# Function to decide next step\n",
        "def decide_next_step(state: GraphState) -> str:\n",
        "    return state[\"next_step\"]\n",
        "\n",
        "# Create the graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"extract_features\", extract_frame_features)\n",
        "workflow.add_node(\"evaluate_importance\", evaluate_importance)\n",
        "workflow.add_node(\"describe_frame\", describe_frame)\n",
        "\n",
        "# Define graph transitions\n",
        "workflow.add_edge(\"extract_features\", \"evaluate_importance\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"evaluate_importance\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        \"describe_frame\": \"describe_frame\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"describe_frame\", END)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"extract_features\")\n",
        "\n",
        "# Compile the graph\n",
        "frame_processor = workflow.compile()\n",
        "\n",
        "# Function to save frame description to CSV\n",
        "def save_description_to_csv(result: Dict[str, Any]):\n",
        "    \"\"\"Save important frame description to CSV file\"\"\"\n",
        "    # Check for description information\n",
        "    if \"description\" not in result or not result[\"description\"]:\n",
        "        print(f\"  No description available for frame: {result.get('frame', '')}\")\n",
        "        return False\n",
        "\n",
        "    description = result[\"description\"]\n",
        "\n",
        "    # Prepare row data\n",
        "    row = {\n",
        "        \"Image Name\": description.get(\"image_name\", os.path.basename(result.get(\"path\", \"\"))),\n",
        "        \"Extracted Text\": description.get(\"extracted_text\", \"No extracted text\"),\n",
        "        \"Visual Description\": description.get(\"visual_description\", \"No visual description\")\n",
        "    }\n",
        "\n",
        "    # Print information for verification\n",
        "    print(f\"  Extracted text ({len(row['Extracted Text'])} chars): {row['Extracted Text'][:50]}...\")\n",
        "    print(f\"  Visual description ({len(row['Visual Description'])} chars): {row['Visual Description'][:50]}...\")\n",
        "\n",
        "    # Check if file exists to determine if header should be written\n",
        "    file_exists = os.path.exists(output_csv_file)\n",
        "\n",
        "    try:\n",
        "        with open(output_csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=[\"Image Name\", \"Extracted Text\", \"Visual Description\"])\n",
        "\n",
        "            if not file_exists:\n",
        "                writer.writeheader()\n",
        "\n",
        "            writer.writerow(row)\n",
        "\n",
        "        print(f\"  Frame description saved to {output_csv_file}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\" Error saving frame description: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# Function to process a single frame\n",
        "def process_single_frame(frame_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"Process a single video frame: classify and if important, describe it\"\"\"\n",
        "    initial_state = {\n",
        "        \"frame_path\": frame_path,\n",
        "        \"frame_data\": {},\n",
        "        \"frame_features\": {},\n",
        "        \"importance\": \"not_important\",\n",
        "        \"reason\": \"\",\n",
        "        \"description\": {},\n",
        "        \"next_step\": \"extract_features\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Execute the graph\n",
        "        result = frame_processor.invoke(initial_state)\n",
        "\n",
        "        # Prepare basic result - WITHOUT features\n",
        "        output = {\n",
        "            \"frame\": os.path.basename(frame_path),\n",
        "            \"path\": frame_path,\n",
        "            \"importance\": result[\"importance\"],\n",
        "            \"reason\": result[\"reason\"],\n",
        "        }\n",
        "\n",
        "        # Add description if frame is important\n",
        "        if result[\"importance\"] == \"important\":\n",
        "            # Ensure description information exists\n",
        "            if \"description\" in result and isinstance(result[\"description\"], dict) and result[\"description\"]:\n",
        "                output[\"description\"] = result[\"description\"]\n",
        "            else:\n",
        "                print(f\"  Warning: No description extracted for important frame: {os.path.basename(frame_path)}\")\n",
        "                # Try to describe the frame directly if not described through the graph\n",
        "                try:\n",
        "                    # Use direct description function - WITHOUT retries\n",
        "                    output[\"description\"] = describe_frame_directly(frame_path)\n",
        "                    print(f\"   Description extracted successfully on second attempt\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   Failed to extract description: {str(e)}\")\n",
        "                    output[\"description\"] = {\n",
        "                        \"image_name\": os.path.basename(frame_path),\n",
        "                        \"extracted_text\": \"Failed to extract text\",\n",
        "                        \"visual_description\": \"Failed to extract visual description\",\n",
        "                        \"error\": str(e)\n",
        "                    }\n",
        "\n",
        "        return output\n",
        "    except Exception as e:\n",
        "        print(f\"  Error processing frame: {str(e)}\")\n",
        "        return {\n",
        "            \"frame\": os.path.basename(frame_path),\n",
        "            \"path\": frame_path,\n",
        "            \"importance\": \"error\",\n",
        "            \"reason\": f\"Processing error: {str(e)}\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# Function to process a set of frames\n",
        "def process_frames(frame_paths: List[str]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Process a set of video frames and evaluate their importance and describe important ones\"\"\"\n",
        "    results = []\n",
        "    important_frames_count = 0\n",
        "\n",
        "    for i, frame_path in enumerate(frame_paths):\n",
        "        print(f\"Processing frame {i+1}/{len(frame_paths)}: {os.path.basename(frame_path)}\")\n",
        "\n",
        "        try:\n",
        "            result = process_single_frame(frame_path)\n",
        "            results.append(result)\n",
        "\n",
        "            if result[\"importance\"] == \"important\":\n",
        "                important_frames_count += 1\n",
        "                print(f\"   Important: {result['reason'][:50]}...\")\n",
        "\n",
        "                # Ensure description exists\n",
        "                if \"description\" not in result or not result[\"description\"]:\n",
        "                    print(f\"  Retrying description for important frame...\")\n",
        "                    # Call frame description again directly - WITHOUT retries\n",
        "                    try:\n",
        "                        result[\"description\"] = describe_frame_directly(frame_path)\n",
        "                        print(f\"  Description extracted successfully on retry\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"  Retry failed: {str(e)}\")\n",
        "\n",
        "                # Save important frame description to CSV\n",
        "                if \"description\" in result and result[\"description\"]:\n",
        "                    save_description_to_csv(result)\n",
        "            else:\n",
        "                print(f\"   Not important: {result['reason'][:50]}...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing frame: {str(e)}\")\n",
        "            results.append({\n",
        "                \"frame\": os.path.basename(frame_path),\n",
        "                \"path\": frame_path,\n",
        "                \"importance\": \"error\",\n",
        "                \"reason\": str(e)\n",
        "            })\n",
        "\n",
        "    print(f\"\\nFound {important_frames_count} important frames out of {len(frame_paths)}\")\n",
        "    return results\n",
        "\n",
        "# Function to read frames from a folder\n",
        "def get_frames_from_folder(folder_path: str, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.tiff')) -> List[str]:\n",
        "    \"\"\"Extract paths of all image files from a specified folder\"\"\"\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: Folder {folder_path} does not exist\")\n",
        "        return []\n",
        "\n",
        "    frame_paths = []\n",
        "    for ext in extensions:\n",
        "        frame_paths.extend(glob.glob(os.path.join(folder_path, f'*{ext}')))\n",
        "\n",
        "    # Sort files to ensure they're processed in a logical order\n",
        "    frame_paths.sort()\n",
        "\n",
        "    print(f\"Found {len(frame_paths)} frames in folder {folder_path}\")\n",
        "    return frame_paths\n",
        "\n",
        "# Main function\n",
        "def main(frames_folder: str):\n",
        "    \"\"\"Main function to process frames in a folder\"\"\"\n",
        "    # Ensure output folder exists\n",
        "    os.makedirs(\"output\", exist_ok=True)\n",
        "\n",
        "    # Get list of all frames in folder\n",
        "    frame_paths = get_frames_from_folder(frames_folder)\n",
        "\n",
        "    if not frame_paths:\n",
        "        print(\"No frames found for processing!\")\n",
        "        return\n",
        "\n",
        "    # Process frames\n",
        "    results = process_frames(frame_paths)\n",
        "\n",
        "    # Save classification results to JSON file\n",
        "    with open(output_json_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        # Remove features from output - already handled in process_single_frame\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Classification results saved to {output_json_file}\")\n",
        "\n",
        "    # Analyze results\n",
        "    important_frames = [r for r in results if r[\"importance\"] == \"important\"]\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\n--- Results Summary ---\")\n",
        "    print(f\"Total frames: {len(results)}\")\n",
        "    print(f\"Important frames: {len(important_frames)}\")\n",
        "    print(f\"Unimportant frames: {len(results) - len(important_frames)}\")\n",
        "    print(f\"Important frame descriptions saved to: {output_csv_file}\")\n",
        "    print(f\"Classification results saved to: {output_json_file}\")\n",
        "\n",
        "    # Display additional information about important frames\n",
        "    if important_frames:\n",
        "        print(\"\\n--- Important Frames ---\")\n",
        "        for i, frame in enumerate(important_frames):\n",
        "            print(f\"{i+1}. {frame['frame']}: {frame['reason'][:100]}...\")\n",
        "\n",
        "# Google Colab Helper Functions\n",
        "def setup_for_colab():\n",
        "    \"\"\"Setup environment for Google Colab\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"Running in Google Colab environment\")\n",
        "        return True\n",
        "    except:\n",
        "        print(\"Not running in Google Colab environment\")\n",
        "        return False\n",
        "\n",
        "def upload_images_to_colab():\n",
        "    \"\"\"Function to handle image uploads in Google Colab\"\"\"\n",
        "    from google.colab import files\n",
        "\n",
        "    # Create upload folder\n",
        "    upload_folder = \"/content/uploaded_images\"\n",
        "    os.makedirs(upload_folder, exist_ok=True)\n",
        "\n",
        "    print(\"Please upload your video frames (image files)\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Save uploaded files to the folder\n",
        "    for filename, content in uploaded.items():\n",
        "        file_path = os.path.join(upload_folder, filename)\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            f.write(content)\n",
        "\n",
        "    print(f\"Uploaded {len(uploaded)} files to {upload_folder}\")\n",
        "    return upload_folder\n",
        "\n",
        "def download_results_from_colab():\n",
        "    \"\"\"Function to download results in Google Colab\"\"\"\n",
        "    from google.colab import files\n",
        "\n",
        "    # Download CSV and JSON files\n",
        "    if os.path.exists(output_csv_file):\n",
        "        files.download(output_csv_file)\n",
        "        print(f\"Downloaded {output_csv_file}\")\n",
        "\n",
        "    if os.path.exists(output_json_file):\n",
        "        files.download(output_json_file)\n",
        "        print(f\"Downloaded {output_json_file}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldsGtf5hF5vQ"
      },
      "source": [
        "# Helper function to convert image to base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGQy2xZWE-uc"
      },
      "outputs": [],
      "source": [
        "# Call main function when file is executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if running in Google Colab\n",
        "    if setup_for_colab():\n",
        "        # Handle file uploads in Colab\n",
        "        FRAMES_FOLDER = upload_images_to_colab()\n",
        "\n",
        "        # Process frames\n",
        "        main(FRAMES_FOLDER)\n",
        "\n",
        "        # Download results\n",
        "        download_results_from_colab()\n",
        "    else:\n",
        "        # If not in Colab, specify frames folder directly\n",
        "        FRAMES_FOLDER = \"frames\"  # Change this to your actual folder path\n",
        "\n",
        "        # Create folder if it doesn't exist\n",
        "        os.makedirs(FRAMES_FOLDER, exist_ok=True)\n",
        "\n",
        "        # Process frames\n",
        "        main(FRAMES_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jht4THEhV6XK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
