{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfb21e2",
   "metadata": {},
   "source": [
    "## Optimized virsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6dbe79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e10d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp(frame_idx, fps):\n",
    "    seconds = frame_idx / fps\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}.{ms:03d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ac1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, interval_sec=3):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0:\n",
    "        fps = 30\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = int(fps * interval_sec)\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for frame_idx in range(0, total_frames, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        records.append((frame, frame_idx))\n",
    "\n",
    "    cap.release()\n",
    "    return records, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a63f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keyframes(records, hash_threshold=5, ssim_threshold=0.90, ssim_compare_window=3):\n",
    "    hasher = cv2.img_hash.PHash_create()\n",
    "    seen_hashes = []\n",
    "    distinct_records = []\n",
    "\n",
    "    for frame, frame_idx in records:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        resized_gray = cv2.resize(gray, (128, 128))\n",
    "\n",
    "        img_hash = hasher.compute(frame)\n",
    "        is_duplicate_hash = any(cv2.norm(img_hash, h, cv2.NORM_HAMMING) <= hash_threshold for h in seen_hashes)\n",
    "        if is_duplicate_hash:\n",
    "            continue\n",
    "        seen_hashes.append(img_hash)\n",
    "\n",
    "        is_distinct_ssim = True\n",
    "        for prev_frame, _ in distinct_records[-ssim_compare_window:]:\n",
    "            prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "            prev_resized = cv2.resize(prev_gray, (128, 128))\n",
    "            if ssim(resized_gray, prev_resized) > ssim_threshold:\n",
    "                is_distinct_ssim = False\n",
    "                break\n",
    "\n",
    "        if is_distinct_ssim:\n",
    "            distinct_records.append((frame, frame_idx))\n",
    "\n",
    "    return distinct_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3b7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model.eval()\n",
    "\n",
    "def get_clip_embedding(frame):\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = clip_model.get_image_features(**inputs)\n",
    "        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "def filter_keyframes_clip(records, similarity_threshold=0.85, compare_window=5):\n",
    "    distinct_records = []\n",
    "    past_embeddings = []\n",
    "\n",
    "    for frame, frame_idx in records:\n",
    "        emb = get_clip_embedding(frame)\n",
    "\n",
    "        is_distinct = True\n",
    "        for prev_emb in past_embeddings[-compare_window:]:\n",
    "            sim = cosine_similarity([emb], [prev_emb])[0][0]\n",
    "            if sim > similarity_threshold:\n",
    "                is_distinct = False\n",
    "                break\n",
    "\n",
    "        if is_distinct:\n",
    "            distinct_records.append((frame, frame_idx))\n",
    "            past_embeddings.append(emb)\n",
    "\n",
    "    return distinct_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8444a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_records_to_disk(records, output_dir, output_csv, fps):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    with open(output_csv, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"keyframe\", \"timestamp\"])\n",
    "\n",
    "        for i, (frame, frame_idx) in enumerate(records):\n",
    "            frame_name = f\"keyframe_{i:04d}.jpg\"\n",
    "            out_path = os.path.join(output_dir, frame_name)\n",
    "            cv2.imwrite(out_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n",
    "            timestamp = get_timestamp(frame_idx, fps)\n",
    "            writer.writerow([out_path, timestamp])\n",
    "\n",
    "    return pd.read_csv(output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d647a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"keyframes\"\n",
    "output_csv = \"keyframes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c4fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: raw_videos\\Dr. Mohamed Ismail (720p, h264).mp4\n",
      "Extracted 104 frames from video at 29.97002997002997 FPS.\n",
      "Filtering keyframes using hash and SSIM...\n",
      "Filtering keyframes using CLIP...\n",
      "Saving 16 keyframes to disk...\n",
      "\n",
      "Processing video: raw_videos\\Filters - Mohammad Ayed (720p, h264).mp4\n",
      "Extracted 441 frames from video at 29.97002997002997 FPS.\n",
      "Filtering keyframes using hash and SSIM...\n",
      "Filtering keyframes using CLIP...\n",
      "Saving 20 keyframes to disk...\n",
      "\n",
      "Processing video: raw_videos\\Linear Regression - Hesham Asem (720p, h264).mp4\n",
      "Extracted 394 frames from video at 25.0 FPS.\n",
      "Filtering keyframes using hash and SSIM...\n",
      "Filtering keyframes using CLIP...\n",
      "Saving 10 keyframes to disk...\n",
      "\n",
      "Processing video: raw_videos\\Perceptual Hashing To Compare Images Explained - Cryptography for Everybody (720p, h264).mp4\n",
      "Extracted 353 frames from video at 29.97002997002997 FPS.\n",
      "Filtering keyframes using hash and SSIM...\n",
      "Filtering keyframes using CLIP...\n",
      "Saving 18 keyframes to disk...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v in os.listdir(\"raw_videos\"):\n",
    "    video_path = os.path.join(\"raw_videos\", v)\n",
    "    if not os.path.isfile(video_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    records, fps = process_video(video_path, interval_sec=3)\n",
    "    print(f\"Extracted {len(records)} frames from video at {fps} FPS.\")\n",
    "    \n",
    "    print(\"Filtering keyframes using hash and SSIM...\")\n",
    "    filtered_records = filter_keyframes(records, hash_threshold=5, ssim_threshold=0.95, ssim_compare_window=5)\n",
    "    \n",
    "    print(\"Filtering keyframes using CLIP...\")\n",
    "    final_records = filter_keyframes_clip(filtered_records, similarity_threshold=0.90, compare_window=5)\n",
    "    \n",
    "    print(f\"Saving {len(final_records)} keyframes to disk...\\n\")\n",
    "    output_dir = os.path.join(\"keyframes\", os.path.splitext(v)[0])\n",
    "    output_csv = os.path.join(output_dir, \"keyframes.csv\")\n",
    "    save_records_to_disk(final_records, output_dir, output_csv, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe09131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
