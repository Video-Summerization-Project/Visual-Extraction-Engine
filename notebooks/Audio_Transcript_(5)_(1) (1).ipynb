{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50ac0f39",
      "metadata": {
        "id": "50ac0f39"
      },
      "source": [
        "# $Audio Transcript$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9cafe56",
      "metadata": {
        "id": "f9cafe56"
      },
      "source": [
        "## `01` Import Libs:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain pillow pytesseract transformers torch torchvision pandas"
      ],
      "metadata": {
        "id": "CJP-U37pT-KC"
      },
      "id": "CJP-U37pT-KC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "WFPoe7O5Vy6g"
      },
      "id": "WFPoe7O5Vy6g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2836254c",
      "metadata": {
        "id": "2836254c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from langchain.agents import initialize_agent, AgentType, Tool\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.router import MultiPromptChain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from langchain_core.messages import HumanMessage\n"
      ],
      "metadata": {
        "id": "e_6ee7mhB9R6"
      },
      "id": "e_6ee7mhB9R6",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3d729151",
      "metadata": {
        "id": "3d729151"
      },
      "source": [
        "## `02` API setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9d32356d",
      "metadata": {
        "id": "9d32356d"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "genai.configure(api_key= GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77cdd0db",
      "metadata": {
        "id": "77cdd0db"
      },
      "source": [
        "## Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7a434028",
      "metadata": {
        "id": "7a434028"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775ad371",
      "metadata": {
        "id": "775ad371"
      },
      "source": [
        "## Load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "97d99d03",
      "metadata": {
        "id": "97d99d03"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"output\", exist_ok=True)\n",
        "output_csv_file = \"output/results.csv\"\n",
        "image_dir = '/content/images'\n",
        "image_pattern = '*.jpg'\n",
        "image_paths = glob.glob(os.path.join(image_dir, image_pattern))\n",
        "csv_headers = [\"Image Name\", \"Extracted Text\", \"Visual Description\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62976b10",
      "metadata": {
        "id": "62976b10"
      },
      "source": [
        "## helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9c77c2a7",
      "metadata": {
        "id": "9c77c2a7"
      },
      "outputs": [],
      "source": [
        "def get_dummy_image(original_path):\n",
        "    \"\"\"\n",
        "    This function loads an image and returns an in-memory copy of it.\n",
        "    It does not save anything to disk.\n",
        "    Parameters:\n",
        "        original_path (str): The path to the original image file.\n",
        "    Returns:\n",
        "        PIL.Image: An in-memory copy of the original image.\n",
        "    \"\"\"\n",
        "    original = Image.open(original_path)\n",
        "    buffer = BytesIO()\n",
        "    original.save(buffer, format=original.format)  # Save to memory buffer\n",
        "    buffer.seek(0)\n",
        "    return Image.open(buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea0a0b02",
      "metadata": {
        "id": "ea0a0b02"
      },
      "source": [
        "## Agent tools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extract text and discription"
      ],
      "metadata": {
        "id": "GDAWRg4GijUs"
      },
      "id": "GDAWRg4GijUs"
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_with_vision(image_path):\n",
        "    # Open and process the image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Convert image to base64 string\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=image.format)\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
        "    mime_type = f\"image/{image.format.lower()}\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "        You are an expert in multilingual document understanding.\n",
        "\n",
        "        Your job is to extract and analyze the text and informative visuals from the given image.\n",
        "\n",
        "        Rules:\n",
        "          -Analyze the provided images to extract all textual content.\n",
        "          -If the text is in Arabic, transcribe it in Arabic and provide an English translation in quotation marks immediately following the Arabic text.\n",
        "          -If the text is entirely in English, transcribe it as is.\n",
        "          -If the text is predominantly Arabic with some English words, transcribe the Arabic and enclose the English words in quotation marks within the Arabic transcription.\n",
        "          -Additionally, identify and describe any *embedded, informative visuals* within the images that convey data or information.\n",
        "          -This specifically includes elements such as graphs, charts, tables of text, histograms, flowcharts, diagrams, or other visual representations of data.\n",
        "          -Do NOT describe the overall image design, background, or purely decorative elements.\n",
        "          -Structure the output as follows, with each image's information presented in a clear, column-like format:\n",
        "\n",
        "        Image Name: {os.path.basename(image_path)}\n",
        "        Extracted Text: [Transcribed text as per language rules, with English translations/quoted English words]\n",
        "        Visual Description: [Detailed description of any embedded, informative visuals present. State 'None' if no such visuals are found.]\n",
        "        \"\"\"\n",
        "\n",
        "    # Create properly formatted message for Gemini\n",
        "    message = HumanMessage(\n",
        "        content=[\n",
        "            {\"type\": \"text\", \"text\": prompt},\n",
        "            {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\n",
        "                    \"url\": f\"data:{mime_type};base64,{img_str}\"\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    result = llm.invoke([message])\n",
        "    return result.content.strip()\n",
        "\n",
        "\"********************************************************************************************\"\n",
        "\n",
        "# Initialize the tool correctly\n",
        "discription_tool = Tool.from_function(\n",
        "    name=\"OCRwithVision\",\n",
        "    func=extract_text_with_vision,\n",
        "    description=\"Performs OCR and visual analysis using Gemini Vision model\"\n",
        ")"
      ],
      "metadata": {
        "id": "1WVc9n1wCPv5"
      },
      "id": "1WVc9n1wCPv5",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###convert to rows"
      ],
      "metadata": {
        "id": "eNozadr2jvit"
      },
      "id": "eNozadr2jvit"
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_model_output_to_rows(model_output_text, output_csv_file=output_csv_file, csv_headers=csv_headers):\n",
        "    try:\n",
        "        # Improved parsing with more robust pattern matching\n",
        "        image_name_match = re.search(r'Image Name:\\s*(.*?)\\s*(?=Extracted Text:|Visual Description:|$)',\n",
        "                                   model_output_text, re.DOTALL | re.IGNORECASE)\n",
        "        extracted_text_match = re.search(r'Extracted Text:\\s*(.*?)\\s*(?=Visual Description:|$)',\n",
        "                                       model_output_text, re.DOTALL | re.IGNORECASE)\n",
        "        visual_description_match = re.search(r'Visual Description:\\s*(.*)',\n",
        "                                           model_output_text, re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "        image_name = image_name_match.group(1).strip() if image_name_match else \"N/A\"\n",
        "        extracted_text = extracted_text_match.group(1).strip() if extracted_text_match else \"N/A\"\n",
        "        visual_description = visual_description_match.group(1).strip() if visual_description_match else \"N/A\"\n",
        "\n",
        "        # Clean up text\n",
        "        extracted_text = extracted_text.replace(\"<br>\", \"\\n\").replace(\"<br/>\", \"\\n\")\n",
        "\n",
        "        # Create the row dictionary\n",
        "        row_to_save = {\n",
        "            \"Image Name\": image_name,\n",
        "            \"Extracted Text\": extracted_text,\n",
        "            \"Visual Description\": visual_description\n",
        "        }\n",
        "\n",
        "        # Write to CSV\n",
        "        file_exists = os.path.exists(output_csv_file)\n",
        "        write_header = not file_exists or os.path.getsize(output_csv_file) == 0\n",
        "\n",
        "        with open(output_csv_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
        "            writer = csv.DictWriter(csvfile, fieldnames=csv_headers)\n",
        "\n",
        "            if write_header:\n",
        "                writer.writeheader()\n",
        "\n",
        "            writer.writerow(row_to_save)\n",
        "\n",
        "        print(f\"Data for '{image_name}' saved to {output_csv_file}\")\n",
        "        return f\"Successfully saved data for {image_name} to CSV\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error parsing model output: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "# Initialize the tool correctly\n",
        "export_csv_tool = Tool.from_function(\n",
        "    name=\"ExportCSV\",\n",
        "    func=parse_model_output_to_rows,\n",
        "    description=\"Parses model output and saves image data to CSV file\"\n",
        ")\n",
        "\n",
        "# Create a new tool to handle the CSV saving\n",
        "def save_to_csv_wrapper(model_output):\n",
        "    \"\"\"Wrapper function to save model output to CSV\"\"\"\n",
        "    result = parse_model_output_to_rows(model_output)\n",
        "    return result\n",
        "\n",
        "'**************************************************************************************************************************'\n",
        "\n",
        "csv_save_tool = Tool.from_function(\n",
        "    name=\"SaveToCSV\",\n",
        "    func=save_to_csv_wrapper,\n",
        "    description=\"Saves the extracted information to a CSV file\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "mtL0XAANOoTR"
      },
      "id": "mtL0XAANOoTR",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_descriptions(descriptions):\n",
        "    \"\"\"Summarize multiple visual descriptions using LLM\"\"\"\n",
        "    prompt = \"\"\"\n",
        "    You are an expert in translation and summarizing visual content descriptions.\n",
        "    Please provide a concise summary of the following visual descriptions:\n",
        "\n",
        "    {descriptions}\n",
        "\n",
        "    Summary should:\n",
        "    - Highlight common themes\n",
        "    - Identify key information patterns\n",
        "    - the summurization should be in Arabic\n",
        "    - Be 4-6 sentences maximum\n",
        "    \"\"\"\n",
        "\n",
        "    combined = \"\\n\\n\".join(descriptions)\n",
        "\n",
        "    # Generate summary\n",
        "    result = llm.invoke(prompt.format(descriptions=combined))\n",
        "    return result.content"
      ],
      "metadata": {
        "id": "rEGFnsRbC6NZ"
      },
      "id": "rEGFnsRbC6NZ",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [discription_tool, export_csv_tool]\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "gKCDgd7JlWxl"
      },
      "id": "gKCDgd7JlWxl",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_prompt = \"\"\"\n",
        "You are a helpful assistant that can process images, extract information, and save it to a CSV file using provided tools.\n",
        "\n",
        "Your task is to process the image located at {image_path}.\n",
        "Follow these steps:\n",
        "1. **Think**: I need to process the image.\n",
        "2. **Action**: Use the `OCRwithVision` tool to extract text and visual descriptions from the image.\n",
        "3. **Think**: I need to extract data to extract text and visual descriptions .\n",
        "5. **Action Input**: Provide the image path: {image_path}\n",
        "6. **Observation**: [The output from the OCRwithVision tool will appear here]\n",
        "7. **Think**: I have the extracted data. Now I need to format it and save it to a CSV file using the `ExportCSV` tool.\n",
        "8. **Action**: Use the `ExportCSV` tool.\n",
        "9. **Action Input**: Provide the output from nthe `OCRwithVision` tool which needs to be parsed and saved.\n",
        "10. **Observation**: [The output from the ExportCSV tool will appear here]\n",
        "11. **Think**: The data has been saved to the CSV file.\n",
        "12. **Final Answer**: The image has been processed, and the extracted information has been saved to the CSV file.\n",
        "\n",
        "Begin!\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "i3fcyJIwqNLM"
      },
      "id": "i3fcyJIwqNLM",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(output_csv_file):\n",
        "    with open(output_csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=csv_headers)\n",
        "        writer.writeheader()\n",
        "\n",
        "for image_path in image_paths:\n",
        "    try:\n",
        "        print(f\"Processing image: {image_path}\")\n",
        "\n",
        "        result = agent.invoke({\n",
        "         \"input\": agent_prompt.format(image_path=image_path)\n",
        "         })\n",
        "        print(f\"Result for {image_path}: {result}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "print(\"All images processed and results saved to CSV.\")"
      ],
      "metadata": {
        "id": "Ro8l4RxALqVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320525e1-973c-489d-c453-1d887951942c"
      },
      "id": "Ro8l4RxALqVj",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image: /content/images/keyframe_0003.jpg\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 50\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 30\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought:I need to perform OCR on the image using the OCRwithVision tool.\n",
            "\n",
            "Action:\n",
            "```json\n",
            "{\n",
            "  \"action\": \"OCRwithVision\",\n",
            "  \"action_input\": \"/content/images/keyframe_0003.jpg\"\n",
            "}\n",
            "```\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 50\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 28\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /content/images/keyframe_0003.jpg: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 50\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 28\n",
            "}\n",
            "]\n",
            "Processing image: /content/images/keyframe_0002.jpg\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 50\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 26\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing /content/images/keyframe_0002.jpg: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 50\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 26\n",
            "}\n",
            "]\n",
            "Processing image: /content/images/keyframe_0004.jpg\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "Error processing /content/images/keyframe_0004.jpg: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-1.5-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 50\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 24\n",
            "}\n",
            "]\n",
            "All images processed and results saved to CSV.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discription = pd.read_csv(output_csv_file)\n",
        "discription = discription['Extracted Text']\n",
        "final_result = summarize_descriptions(discription)\n",
        "print(final_result)"
      ],
      "metadata": {
        "id": "uNXDV34xGtRD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "480ac941-3d29-474f-af73-9b07cf230ef8"
      },
      "id": "uNXDV34xGtRD",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "sequence item 0: expected str instance, float found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-39-873191451.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_csv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdiscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscription\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Extracted Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_descriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-35-1012087265.py\u001b[0m in \u001b[0;36msummarize_descriptions\u001b[0;34m(descriptions)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Generate summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, float found"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}