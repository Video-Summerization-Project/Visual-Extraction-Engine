# Visual Extraction Engine

An AI-powered engine for extracting and summarizing key visual content from video lectures using LLM agents, OCR, and graph-based workflows. This tool is optimized for downstream applications like educational summarization, content indexing, or tagging.

---

## ğŸš€ Features
- Intelligent keyframe selection based on visual and semantic importance
- Frame-level summarization using LangChain-compatible LLM agents
- OCR for slide and board content
- Modular graph-based frame processing pipeline
- Easy-to-configure paths and IO logic

---

## ğŸš§ Installation

```bash
git clone https://github.com/Video-Summerization-Project/Visual-Extraction-Engine.git
cd Visual-Extraction-Engine
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ”§ Usage

### 1. Prepare Inputs
- Create a `.env` file with required paths or configurations (see `config/paths.py` for reference)
- Add video files to a folder (e.g. `RawVideos/`)

### 2. Run Main Pipeline
```bash
python main.py --video_path RawVideos/example.mp4
```

### 3. Output
- Extracted keyframes: `outputs/keyframes/*.jpg`
- Summaries and tags: `outputs/final_output/results.json`
- CSV of keyframe metadata: `outputs/keyframes.csv`

---

## ğŸ“‚ Project Structure

```
Visual-Extraction-Engine/
â”œâ”€â”€ main.py                        # Entry script
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ config/                       # Path configs
â”‚   â””â”€â”€ paths.py
â”œâ”€â”€ FrameProcessor/               # Main pipeline for frame processing
â”‚   â”œâ”€â”€ main.py                   # Pipeline runner
â”‚   â”œâ”€â”€ graph/                    # Graph-based frame processing workflow
â”‚   â”‚   â”œâ”€â”€ workflow.py
â”‚   â”‚   â””â”€â”€ steps/
â”‚   â”‚       â”œâ”€â”€ describe_frame.py
â”‚   â”‚       â”œâ”€â”€ evaluate_importance.py
â”‚   â”‚       â””â”€â”€ extract_features.py
â”‚   â”œâ”€â”€ ocr/                      # OCR post-processing
â”‚   â”‚   â””â”€â”€ describe_direct.py
â”‚   â”œâ”€â”€ processor/                # Frame-wise processors
â”‚   â”‚   â”œâ”€â”€ multi_frame.py
â”‚   â”‚   â””â”€â”€ single_frame.py
â”‚   â””â”€â”€ utils/                    # Utility functions
â”‚       â”œâ”€â”€ image_utils.py
â”‚       â””â”€â”€ io_utils.py
â”œâ”€â”€ KeyFrameSelection/           # Frame similarity + feature extractor
â”‚   â”œâ”€â”€ FeatureExtraction.py
â”‚   â””â”€â”€ Similarties.py
â”œâ”€â”€ llm/                         # LangChain-based LLM summarizer
â”‚   â””â”€â”€ model.py
â”œâ”€â”€ notebooks/                   # Experiments & analysis
â”‚   â”œâ”€â”€ Scene_detection.ipynb
â”‚   â””â”€â”€ Tags_Agent.ipynb
â”œâ”€â”€ outputs/                     # Final outputs (frames, summaries)
â”‚   â”œâ”€â”€ keyframes.csv
â”‚   â”œâ”€â”€ final_output/results.json
â”‚   â””â”€â”€ keyframes/*.jpg
â”œâ”€â”€ types_/                      # Shared data structures
â”‚   â””â”€â”€ state.py
```

> Note: `.env` file and `RawVideos/` folder are user-dependent and should be created manually.

---


## ğŸ“Š Notebooks
- `Scene_detection.ipynb`: Frame change detection logic
- `Tags_Agent.ipynb`: Experimental LLM-based tag generation

---

## ğŸ“¡ Tech Stack
- Python 3.10+
- OpenCV, Tesseract OCR
- LangChain (LLM agent workflow)
- Custom graph processor architecture

---

## ğŸŒ License
MIT License. See `LICENSE` file for details.

---

## ğŸ Contributors
- [Amr Kahla](https://github.com/AmrKahla)
- [Team Members]

